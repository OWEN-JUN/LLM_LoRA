{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOYg89yg0JTYgHvnAc/lHGh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kA_uHM2xa9Vq"},"outputs":[],"source":["import json\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm import tqdm\n","from sentencepiece import SentencePieceProcessor\n","import os\n","import torch.nn as nn\n","from dataclasses import dataclass\n","from typing import Optional\n","import torch.nn.functional as F\n","import math\n","torch.set_printoptions(sci_mode=False)"]},{"cell_type":"code","source":["\n","# Function to pad a list of tensors to the same length\n","def pad_tensors(list_of_tensors):\n","    tensor_count = len(list_of_tensors) if not torch.is_tensor(list_of_tensors) else list_of_tensors.shape[0]\n","    max_dim = max(t.shape[0] for t in list_of_tensors)  # Find the maximum length\n","    res = []\n","    for t in list_of_tensors:\n","        # Create a zero tensor of the desired shape\n","        res_t = torch.zeros(max_dim, *t.shape[1:]).type(t.dtype).to(t.device)\n","        res_t[:t.shape[0]] = t  # Copy the original tensor into the padded tensor\n","        res.append(res_t)\n","\n","    # Concatenate tensors along a new dimension\n","    res = torch.cat(res)\n","    firstDim = len(list_of_tensors)\n","    secondDim = max_dim\n","\n","    # Reshape the result to have the new dimension first\n","    return res.reshape(firstDim, secondDim, *res.shape[1:])\n","\n","class MyDataset(Dataset):\n","    def __init__(self):\n","        super().__init__()\n","        training_data = {\n","        \"how are you\": \"i am fine <end>\",\n","        \"who is john\": \"a nice person <end>\",\n","        \"who is nice\": \"john <end>\",\n","        \"where is john\": \"at home <end>\",\n","        \"how is john\": \"i dont know <end>\",\n","        \"who are you\": \"mini gpt model <end>\",\n","        \"what is your name\": \"i am a GPT model <end>\",\n","        \"what is GPT\": \"Generative Pre-trained Transformer <end>\",\n","        \"how old are you\": \"I was created recently <end>\",\n","        \"what can you do\": \"I can generate text <end>\",\n","        \"are you intelligent\": \"I try to be <end>\",\n","        \"what is AI\": \"Artificial Intelligence <end>\",\n","        \"who created you\": \"programmers <end>\",\n","        \"where do you live\": \"in the cloud <end>\",\n","        \"do you like humans\": \"I like helping them <end>\",\n","        \"what is your purpose\": \"to assist and provide information <end>\",\n","        \"can you learn\": \"I can be trained on data <end>\",\n","        \"are you alive\": \"I am just a program <end>\",\n","        \"what is your favorite color\": \"I do not have a preference <end>\",\n","        \"do you have emotions\": \"I do not feel emotions <end>\",\n","        \"what is love\": \"a complex human emotion <end>\",\n","        \"can you think\": \"I process information <end>\",\n","        \"do you dream\": \"I do not dream <end>\",\n","        \"what is happiness\": \"a state of well-being <end>\",\n","        \"can you make decisions\": \"I can make choices based on data <end>\",\n","        \"are you human\": \"I am an AI model <end>\"\n","        }\n","\n","        # Extract input and target phrases\n","        data_words = [k for k, _ in training_data.items()]\n","        target_words = [v for _, v in training_data.items()]\n","\n","        # Build vocabulary from training data\n","        self.vocabulary_words = list(set([element.lower() for nestedlist in [x.split(\" \") for x in data_words] for element in nestedlist] + [element.lower() for nestedlist in [x.split(\" \") for x in target_words] for element in nestedlist]))\n","\n","        # Ensure <end> token is at the end of vocabulary list, and there's a blank at the beginning\n","        self.vocabulary_words.remove(\"<end>\")\n","        self.vocabulary_words.append(\"<end>\")\n","        self.vocabulary_words.insert(0, \"\")\n","\n","        # Create mappings from word to index and index to word\n","        self.word_to_ix = {self.vocabulary_words[k].lower(): k for k in range(len(self.vocabulary_words))}\n","        self.ix_to_word = {v: k for k, v in self.word_to_ix.items()}\n","\n","        training_data2 = {\n","        \"how are you\": \"i am fine <end>\",\n","        \"who is john\": \"a nice person <end>\",\n","        \"who is nice\": \"john <end>\",\n","        \"where is john\": \"at home <end>\",\n","        \"how is john\": \"i dont know <end>\",\n","        \"who are you\": \"mini gpt model <end>\",\n","        \"what is your name\": \"i am a GPT model <end>\",\n","        \"what is GPT\": \"Generative Pre-trained Transformer <end>\",\n","        \"how old are you\": \"I was created recently <end>\",\n","        \"what can you do\": \"I can generate text <end>\",\n","        \"are you intelligent\": \"I try to be <end>\",\n","        \"what is AI\": \"Artificial Intelligence <end>\",\n","        \"who created you\": \"programmers <end>\",\n","        \"where do you live\": \"in the cloud <end>\",\n","        \"do you like humans\": \"I like helping them <end>\",\n","        \"what is your purpose\": \"to assist and provide information <end>\",\n","        \"can you learn\": \"I can be trained on data <end>\",\n","        \"are you alive\": \"I am just a program <end>\",\n","        \"what is your favorite color\": \"I do not have a preference <end>\",\n","        \"do you have emotions\": \"I do not feel emotions <end>\",\n","        \"what is love\": \"a complex human emotion <end>\",\n","        \"can you think\": \"I process information <end>\",\n","        \"do you dream\": \"I do not dream <end>\",\n","        }\n","\n","        # Extract input and target phrases\n","        data_words = [k for k, _ in training_data2.items()]\n","        target_words = [v for _, v in training_data2.items()]\n","        data_words_tensor = self.Encode(data_words)\n","        target_words_tensor = self.Encode(target_words)\n","\n","\n","\n","        self.input_ids = torch.cat((data_words_tensor, target_words_tensor),1)\n","\n","\n","\n","\n","\n","    def Decode(self, x : torch.Tensor):\n","        index_batch = torch.tensor(x).cpu().numpy().tolist()\n","        # print(\"index_batch\",index_batch)\n","        res = []\n","        for indices in index_batch:\n","            words = []\n","            for ix in indices:\n","                words.append(self.ix_to_word[ix].lower())  # Convert index to word\n","                if ix == self.word_to_ix[\"<end>\"]:\n","                    break  # Stop when <end> token is encountered\n","            res.append(\" \".join(words))\n","        return res\n","\n","    def Encode(self, seq_batch, device = None):\n","        index_batch = []\n","\n","        # Loop over sequences in the batch\n","        for seq in seq_batch:\n","            word_list = seq.lower().split(\" \")\n","            indices = [self.word_to_ix[word] for word in word_list if word in self.word_to_ix]\n","            t = torch.tensor(indices)\n","            if device is not None:\n","                t = t.to(device)  # Transfer tensor to the specified device\n","            index_batch.append(t)\n","\n","        # Pad tensors to have the same length\n","        return pad_tensors(index_batch)\n","    def vocab_size(self):\n","        return len(self.vocabulary_words)\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        return self.input_ids[idx]\n","\n","\n","\n","\n","\n","\n","tokenizer = MyDataset()\n","train_dataloader = DataLoader(tokenizer, batch_size=4, shuffle=True)\n","tokenizer.vocab_size()\n","# train_dataloader = DataLoader(train_dataset, batch_size=3, collate_fn=collate_fn, shuffle=True, pin_memory=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ffw6bN6bA0l","executionInfo":{"status":"ok","timestamp":1713934581454,"user_tz":-540,"elapsed":508,"user":{"displayName":"진이준","userId":"14331068232004822154"}},"outputId":"ccfaa91a-47f4-42b9-caf8-84a3c4c6692f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["87"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["\n","@dataclass\n","class ModelArgs:\n","    dim: int = 512\n","    n_layers: int = 4\n","    n_heads: int = 4\n","    vocab_size: int = -1\n","    multiple_of: int = 256\n","    norm_eps: float = 1e-5\n","\n","def look_ahead_mask( seq_len):\n","    mask = torch.full([seq_len, seq_len], float(\"-inf\"))\n","    mask = torch.triu(mask, diagonal=1)\n","\n","    return mask\n","\n","class RMSNorm(nn.Module):\n","    def __init__(self, dim: int, eps:float = 1e-6):\n","        super().__init__()\n","        self.eps = eps\n","        self.weight = nn.Parameter(torch.ones(dim))\n","\n","    def _norm(self, x: torch.Tensor):\n","        #(B,seq_len, dim) * (B,seq_len,1) = (B,seq_len,dim)\n","        #rsqrt: 1/sqrt(x)\n","        return x * torch.rsqrt(x.pow(2).mean(-1,keepdim=True)+self.eps)\n","\n","    def forward(self, x: torch.Tensor):\n","        return self.weight * self._norm(x.float()).type_as(x)\n","\n","class SelfAttention(nn.Module):\n","\n","    def __init__(self, args: ModelArgs):\n","        super().__init__()\n","\n","\n","        self.n_heads = args.n_heads\n","        self.head_dim = args.dim // args.n_heads\n","\n","        self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n","        self.wk = nn.Linear(args.dim, self.n_heads * self.head_dim, bias=False)\n","        self.wv = nn.Linear(args.dim, self.n_heads * self.head_dim, bias=False)\n","        self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False)\n","\n","\n","\n","\n","    def forward(self, x: torch.Tensor , LH_mask = False, padding_mask = False):\n","        batch_size, seq_len, _ = x.shape # (B, 1, dim)\n","\n","        #(B,1,dim) -->(B,1,head_q * Head_dim)\n","        xq = self.wq(x)\n","        #(B,1,dim) -->(B,1,head_kv * Head_dim)\n","        xk = self.wk(x)\n","        xv = self.wv(x)\n","\n","        #(B,1,head_q * Head_dim) --> (B,1,Head_q, head_dim)\n","        xq = xq.view(batch_size, seq_len, self.n_heads, self.head_dim)\n","        #(B,1,head_kv * Head_dim) --> (B,1,head_kv, head_dim)\n","        xk = xk.view(batch_size, seq_len, self.n_heads, self.head_dim)\n","        xv = xv.view(batch_size, seq_len, self.n_heads, self.head_dim)\n","\n","\n","\n","\n","        #(B, 1, Head_q, Head_dim) -> (B, head_q, 1, Head_dim)\n","        xq = xq.transpose(1,2)\n","\n","        #(B, seq_len_kv, Head_q, head_dim) -> (B, Head_q, seq_len_kv, head_dim)\n","        xk = xk.transpose(1,2)\n","        xv = xv.transpose(1,2)\n","\n","\n","        # (B, Head_q, 1, Head_dim) @ (B, Head_q, Head_dim,seq_len_kv) -> (B, Head_q, 1 ,seq_len_kv)\n","        scores = torch.matmul(xq, xv.transpose(2,3))/math.sqrt(self.head_dim)\n","        if LH_mask ==True:\n","            mask = torch.full([seq_len, seq_len], float(\"-inf\"), device=x.device)\n","            mask = torch.triu(mask, diagonal=1)\n","            scores = scores + mask\n","\n","        if padding_mask != False:\n","            scores = scores + padding_mask\n","        # (B, Head_q, 1, Head_dim) @ (B, Head_q, Head_dim,seq_len_kv) -> (B, Head_q, 1 ,seq_len_kv)\n","        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n","\n","        #(B, Head_q, 1 ,seq_len_kv) @ (B, Head_q, seq_len_kv, head_dim) -> (B, Head_q, 1, head_dim)\n","        output = torch.matmul(scores, xv)\n","        #(B, Head_q, 1, head_dim) -> (B, 1, Head_q, head_dim) -> (B,1,dim)\n","        output = output.transpose(1,2).contiguous().view(batch_size,seq_len,-1)\n","\n","        #(dim.dim) @ (B,1,dim)\n","        return self.wo(output)\n","\n","\n","class FeedForward(nn.Module):\n","    def __init__(self, args: ModelArgs):\n","        super().__init__()\n","        # 4096 * 4 -> 16384\n","        hidden_dim = 4 * args.dim\n","        # (16384 * 2) / 3 -> 10922\n","        hidden_dim = int(2 * hidden_dim / 3)\n","\n","        # 10922 -> 11008\n","        hidden_dim = args.multiple_of * ((hidden_dim + args.multiple_of -1) // args.multiple_of)\n","\n","        self.w1 = nn.Linear(args.dim, hidden_dim, bias = False)\n","        self.w2 = nn.Linear(hidden_dim, args.dim, bias = False)\n","        self.w3 = nn.Linear(args.dim, hidden_dim, bias = False)\n","\n","    def forward(self, x: torch.Tensor):\n","        swish = F.silu(self.w1(x))\n","        x_v = self.w3(x)\n","        x = swish * x_v\n","        x = self.w2(x)\n","        return x\n","\n","\n","\n","class EncoderBlock(nn.Module):\n","    def __init__(self, args: ModelArgs):\n","        super().__init__()\n","\n","        self.n_hjead = args.n_heads\n","        self.dim = args.dim\n","        self.head_dim = args.dim // args.n_heads\n","\n","        self.attention = SelfAttention(args)\n","        self.feed_forward = FeedForward(args)\n","\n","        #Normalization Before the self attention\n","        self.attention_norm = RMSNorm(args.dim, eps = args.norm_eps)\n","        # Normalization Before the feed forward block\n","        self.ffn_norm = RMSNorm(args.dim, eps = args.norm_eps)\n","\n","\n","    def forward(self, x:torch.Tensor,  LH_mask = False, Pad_mask = False):\n","        #(B, seq_len, dim) + (B, seq_len, dim) --> (B, seq_len, dim)\n","        h = x+ self.attention.forward(self.attention_norm(x),  LH_mask)\n","        out = h + self.feed_forward.forward(self.ffn_norm(h))\n","        return out"],"metadata":{"id":"KpXjXjZGdjfS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, dim_model, dropout_p, max_len):\n","        super().__init__()\n","\n","        self.dropout = nn.Dropout(dropout_p)\n","\n","        # Encoding - From formula\n","        pos_encoding = torch.zeros(max_len, dim_model)\n","        positions_list = torch.arange(0, max_len, dtype=torch.float).view(-1, 1) # 0, 1, 2, 3, 4, 5\n","        division_term = torch.exp(torch.arange(0, dim_model, 2).float() * (-math.log(10000.0)) / dim_model) # 1000^(2i/dim_model)\n","\n","        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n","        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n","\n","        # Saving buffer (same as parameter without gradients needed)\n","        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer(\"pos_encoding\", pos_encoding)\n","\n","    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n","        # Residual connection + pos encoding\n","        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])"],"metadata":{"id":"3U5wpF3NdlGZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Transformer(nn.Module):\n","\n","    def __init__(self, args: ModelArgs) -> None:\n","        super().__init__()\n","\n","        assert args.vocab_size != -1, \"Vocab sisze must be set\"\n","\n","        self.args = args\n","        self.vocab_size = args.vocab_size\n","        self.n_layers = args.n_layers\n","        self.tok_embeddings = nn.Embedding(self.vocab_size, args.dim)\n","        self.positional_encoder = PositionalEncoding(dim_model=args.dim, dropout_p=0, max_len=5000)\n","\n","        self.layers = nn.ModuleList()\n","        for _ in range(args.n_layers):\n","            self.layers.append(EncoderBlock(args))\n","\n","        self.norm = RMSNorm(args.dim, eps = args.norm_eps)\n","        self.output = nn.Linear(args.dim, self.vocab_size, bias=False)\n","\n","\n","\n","\n","\n","\n","    def forward(self, tokens: torch.Tensor, LH_mask = False, Pad_mask = False):\n","        # (B, Seq_len)\n","        batch_size, seq_len = tokens.shape\n","        # assert seq_len == 1 # \"only one token at a time can be processed\"\n","\n","        if Pad_mask == True:\n","            padding_mask = (tokens == 0)  # 패딩 토큰은 0으로 되어 있다고 가정합니다.\n","            padding_mask = padding_mask.unsqueeze(1).repeat(1, seq_len, 1) | torch.transpose(padding_mask.unsqueeze(1).repeat(1, seq_len, 1), 2,1)\n","            padding_mask = padding_mask * float(\"-inf\")\n","\n","        # (B. Seq_len) -> (B, Seq_len, Dim)\n","        h = self.tok_embeddings(tokens)\n","        h = self.positional_encoder(h)\n","\n","        #consecutively apply all the encoder layers\n","        for layer in self.layers:\n","            h = layer(h,  LH_mask, padding_mask)\n","        h = self.norm(h)\n","        output = self.output(h).float()\n","        return output"],"metadata":{"id":"k9IUwE2MdmYQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_args: ModelArgs = ModelArgs()"],"metadata":{"id":"f2jmhiyJdnxU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = \"cpu\"\n","# if device == \"cuda\":\n","    # torch.set_default_tensor_type(torch.cuda.HalfTensor)\n","model_args.vocab_size = tokenizer.vocab_size()\n","\n","model = Transformer(model_args).to(device)\n","# model = nn.DataParallel(model, device_ids = [0,1])\n","opt = torch.optim.Adam(model.parameters(), lr=0.0001)\n","loss_fn = nn.CrossEntropyLoss()"],"metadata":{"id":"yBF4xjK0dpNY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_loop(model, opt, loss_fn, dataloader, device, print_random=False):\n","    model.train()\n","    total_loss = 0\n","    max_batches = 700\n","    iteration = 1\n","    # pbar = tqdm(dataloader, position=0, leave=True)\n","    for labels in dataloader:\n","        # X = inputs.to(device)\n","        # print(X.size())\n","        Y = labels.to(device)\n","        padding_mask = Y[:,1:] != 0\n","        # 이제 tgt를 1만큼 이동하여 <SOS>를 사용하여 pos 1에서 토큰을 예측\n","        y_input = Y[:,:-1]\n","        # y_expected = Y[:,1:]\n","        # LH_mask = look_ahead_mask(y_input.size(1)).to(torch.device(device))\n","\n","        # X, y_input 및 tgt_mask를 전달하여 표준 training\n","        pred = model(y_input, LH_mask = True, Pad_mask = True)\n","        # print(str(X.size()) + \" >> \"+str(pred.size()))\n","        # print(y_expected.size())\n","        # Permute 를 수행하여 batch first\n","        if print_random == True:\n","            random_index = torch.randint(0, pred.size(0), (2,))\n","            Y_target = y_input[random_index].to(\"cpu\")\n","            predicted_classes = torch.argmax(pred[random_index], dim=-1).to(\"cpu\")\n","            # print(predicted_classes)\n","            print(\"pred_\",[tokenizer.Decode(pred_.unsqueeze(1)) for pred_ in predicted_classes])\n","            print(\"Y_\",[tokenizer.Decode(Y_.unsqueeze(1)) for Y_ in Y_target])\n","\n","\n","\n","        #total loss cal\n","        # loss = loss_fn(pred, Y[:,1:])\n","\n","        #pad loss cla\n","\n","\n","        loss = F.cross_entropy(pred.reshape(-1,pred.size(2)), Y[:,1:].reshape(-1), reduction='none')\n","\n","        loss = loss.view(Y[:,1:].size())\n","\n","        # print(loss[0])\n","        # 패딩이 아닌 위치의 손실만을 고려하여 평균 손실 계산\n","        loss = torch.sum(loss * padding_mask) / torch.sum(padding_mask)\n","\n","        opt.zero_grad()\n","        loss.backward()\n","        opt.step()\n","\n","        total_loss += loss.detach().item()\n","        iteration += 1\n","        # pbar.set_description(\"loss %s\" % (total_loss/iteration))\n","\n","    return total_loss / len(dataloader)\n","    # return total_loss / max_batches"],"metadata":{"id":"L9YLgJBXdr3C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epoch = 100\n","for i in range(epoch):\n","    loss=train_loop(model, opt, loss_fn, train_dataloader, device)\n","    if (i+1) % 3 == 0:\n","        print(f\"epoch {i+1} || \" +str(loss))\n","\n","    if (i+1) % 100 == 0:\n","        train_loop(model, opt, loss_fn, train_dataloader, device, print_random=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":522},"id":"ffIZI8drdtqh","executionInfo":{"status":"error","timestamp":1713934652645,"user_tz":-540,"elapsed":26230,"user":{"displayName":"진이준","userId":"14331068232004822154"}},"outputId":"47d655c4-b217-44e3-906a-6cbe1088a08b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 3 || 2.63858163356781\n","epoch 6 || 1.3259855310122173\n","epoch 9 || 0.7188119490941366\n","epoch 12 || 0.4775961736838023\n","epoch 15 || 0.32857658962408703\n","epoch 18 || 0.2835540895660718\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-20d0104006ab>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch {i+1} || \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-7d65e2b4a61e>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, opt, loss_fn, dataloader, device, print_random)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m                             )\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 state_steps)\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    167\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    317\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["prompt_ = [\"what is happiness\", \"can you make decisions\",\"are you human\" ,\"how are you\",\"who is john\",\"who is nice\"]\n","model.eval()\n","prompt_tok = tokenizer.Encode(prompt_)\n","end_tok = tokenizer.Encode([\"<end>\"])[-1,-1]\n","max_length = 10\n","total_output = prompt_tok.to(device)\n","# print(total_output)\n","for _ in range(max_length):\n","    out=model(total_output,LH_mask = True, Pad_mask = True)\n","\n","    out=torch.argmax(out, dim=-1)\n","    # print(out[:,-1][0])\n","    # if out[:,-1][0] == end_tok:\n","    #     break\n","\n","    # print( out[:,-1].unsqueeze(-1))\n","    total_output = torch.cat((total_output, out[:,-1].unsqueeze(-1)), 1)\n","\n","tokenizer.Decode(total_output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ks3ByWGXdusk","executionInfo":{"status":"ok","timestamp":1713934655811,"user_tz":-540,"elapsed":891,"user":{"displayName":"진이준","userId":"14331068232004822154"}},"outputId":"4df419ef-2653-47d0-85a6-0ce3f2a9eff0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-2-9dccc5cc9cc1>:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  index_batch = torch.tensor(x).cpu().numpy().tolist()\n"]},{"output_type":"execute_result","data":{"text/plain":["['what is happiness  a complex human emotion <end>',\n"," 'can you make decisions learn can be trained on data <end>',\n"," 'are you human  i am just a program <end>',\n"," 'how are you  i am fine <end>',\n"," 'who is john  a nice person <end>',\n"," 'who is nice  john <end>']"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":[],"metadata":{"id":"tA8p9Xwwd1su"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# LoRA"],"metadata":{"id":"DseKr-1QeTD0"}},{"cell_type":"code","source":["\n","class MyDataset(Dataset):\n","    def __init__(self):\n","        super().__init__()\n","        training_data = {\n","        \"how are you\": \"i am fine <end>\",\n","        \"who is john\": \"a nice person <end>\",\n","        \"who is nice\": \"john <end>\",\n","        \"where is john\": \"at home <end>\",\n","        \"how is john\": \"i dont know <end>\",\n","        \"who are you\": \"mini gpt model <end>\",\n","        \"what is your name\": \"i am a GPT model <end>\",\n","        \"what is GPT\": \"Generative Pre-trained Transformer <end>\",\n","        \"how old are you\": \"I was created recently <end>\",\n","        \"what can you do\": \"I can generate text <end>\",\n","        \"are you intelligent\": \"I try to be <end>\",\n","        \"what is AI\": \"Artificial Intelligence <end>\",\n","        \"who created you\": \"programmers <end>\",\n","        \"where do you live\": \"in the cloud <end>\",\n","        \"do you like humans\": \"I like helping them <end>\",\n","        \"what is your purpose\": \"to assist and provide information <end>\",\n","        \"can you learn\": \"I can be trained on data <end>\",\n","        \"are you alive\": \"I am just a program <end>\",\n","        \"what is your favorite color\": \"I do not have a preference <end>\",\n","        \"do you have emotions\": \"I do not feel emotions <end>\",\n","        \"what is love\": \"a complex human emotion <end>\",\n","        \"can you think\": \"I process information <end>\",\n","        \"do you dream\": \"I do not dream <end>\",\n","        \"what is happiness\": \"a state of well-being <end>\",\n","        \"can you make decisions\": \"I can make choices based on data <end>\",\n","        \"are you human\": \"I am an AI model <end>\"\n","        }\n","\n","        # Extract input and target phrases\n","        data_words = [k for k, _ in training_data.items()]\n","        target_words = [v for _, v in training_data.items()]\n","\n","        # Build vocabulary from training data\n","        self.vocabulary_words = list(set([element.lower() for nestedlist in [x.split(\" \") for x in data_words] for element in nestedlist] + [element.lower() for nestedlist in [x.split(\" \") for x in target_words] for element in nestedlist]))\n","\n","        # Ensure <end> token is at the end of vocabulary list, and there's a blank at the beginning\n","        self.vocabulary_words.remove(\"<end>\")\n","        self.vocabulary_words.append(\"<end>\")\n","        self.vocabulary_words.insert(0, \"\")\n","\n","        # Create mappings from word to index and index to word\n","        self.word_to_ix = {self.vocabulary_words[k].lower(): k for k in range(len(self.vocabulary_words))}\n","        self.ix_to_word = {v: k for k, v in self.word_to_ix.items()}\n","\n","        training_data2 = {\n","\n","        \"what is happiness\": \"a state of well-being <end>\",\n","        \"can you make decisions\": \"I can make choices based on data <end>\",\n","        \"are you human\": \"I am an AI model <end>\"\n","        }\n","\n","        # Extract input and target phrases\n","        data_words = [k for k, _ in training_data2.items()]\n","        target_words = [v for _, v in training_data2.items()]\n","\n","\n","        data_words_tensor = self.Encode(data_words)\n","        target_words_tensor = self.Encode(target_words)\n","\n","\n","\n","        self.input_ids = torch.cat((data_words_tensor, target_words_tensor),1)\n","\n","\n","\n","\n","\n","    def Decode(self, x : torch.Tensor):\n","        index_batch = torch.tensor(x).cpu().numpy().tolist()\n","        # print(\"index_batch\",index_batch)\n","        res = []\n","        for indices in index_batch:\n","            words = []\n","            for ix in indices:\n","                words.append(self.ix_to_word[ix].lower())  # Convert index to word\n","                if ix == self.word_to_ix[\"<end>\"]:\n","                    break  # Stop when <end> token is encountered\n","            res.append(\" \".join(words))\n","        return res\n","\n","    def Encode(self, seq_batch, device = None):\n","        index_batch = []\n","\n","        # Loop over sequences in the batch\n","        for seq in seq_batch:\n","            word_list = seq.lower().split(\" \")\n","            indices = [self.word_to_ix[word] for word in word_list if word in self.word_to_ix]\n","            t = torch.tensor(indices)\n","            if device is not None:\n","                t = t.to(device)  # Transfer tensor to the specified device\n","            index_batch.append(t)\n","\n","        # Pad tensors to have the same length\n","        return pad_tensors(index_batch)\n","    def vocab_size(self):\n","        return len(self.vocabulary_words)\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        return self.input_ids[idx]\n","\n","\n","\n","\n","\n","\n","tokenizer = MyDataset()\n","train_dataloader = DataLoader(tokenizer, batch_size=4, shuffle=True)"],"metadata":{"id":"a2H3tZFueWa1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 기존 모델에서 lora 연결 가능한 레이어 리턴\n","def lora_connect_able(model):\n","        # 모듈의 자식들을 순회합니다.\n","    linear_list = set()\n","    for name, child in model.named_children():\n","        # 자식이 Linear 레이어인 경우\n","        if isinstance(child, nn.Linear):\n","            print( \"Found Linear layer:\", child)\n","            print( \"Found Linear layer name:\", name)\n","            linear_list.add(name)\n","\n","        # 자식이 컨테이너 또는 다른 레이어 타입인 경우, 재귀적으로 내부를 확인합니다.\n","        elif any(isinstance(child, cls) for cls in [nn.ModuleList, EncoderBlock, SelfAttention,FeedForward ]):\n","            print(\"Traversing inside container or custom layer\")\n","            [linear_list.add(e) for e in lora_connect_able(child )]\n","        # 다른 레이어 유형은 무시\n","        else:\n","            continue\n","    return linear_list\n","print(lora_connect_able(model))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EYcS8mhEeZsI","executionInfo":{"status":"ok","timestamp":1713934817023,"user_tz":-540,"elapsed":416,"user":{"displayName":"진이준","userId":"14331068232004822154"}},"outputId":"4c5c543c-d2a3-45cc-cb71-7905f0364786"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Traversing inside container or custom layer\n","Traversing inside container or custom layer\n","Traversing inside container or custom layer\n","Found Linear layer: Linear(in_features=512, out_features=512, bias=False)\n","Found Linear layer name: wq\n","Found Linear layer: Linear(in_features=512, out_features=512, bias=False)\n","Found Linear layer name: wk\n","Found Linear layer: Linear(in_features=512, out_features=512, bias=False)\n","Found Linear layer name: wv\n","Found Linear layer: Linear(in_features=512, out_features=512, bias=False)\n","Found Linear layer name: wo\n","Traversing inside container or custom layer\n","Found Linear layer: Linear(in_features=512, out_features=1536, bias=False)\n","Found Linear layer name: w1\n","Found Linear layer: Linear(in_features=1536, out_features=512, bias=False)\n","Found Linear layer name: w2\n","Found Linear layer: Linear(in_features=512, out_features=1536, bias=False)\n","Found Linear layer name: w3\n","Traversing inside container or custom layer\n","Traversing inside container or custom layer\n","Found Linear layer: Linear(in_features=512, out_features=512, bias=False)\n","Found Linear layer name: wq\n","Found Linear layer: Linear(in_features=512, out_features=512, bias=False)\n","Found Linear layer name: wk\n","Found Linear layer: Linear(in_features=512, out_features=512, bias=False)\n","Found Linear layer name: wv\n","Found Linear layer: Linear(in_features=512, out_features=512, bias=False)\n","Found Linear layer name: wo\n","Traversing inside container or custom layer\n","Found Linear layer: Linear(in_features=512, out_features=1536, bias=False)\n","Found Linear layer name: w1\n","Found Linear layer: Linear(in_features=1536, out_features=512, bias=False)\n","Found Linear layer name: w2\n","Found Linear layer: Linear(in_features=512, out_features=1536, bias=False)\n","Found Linear layer name: w3\n","Traversing inside container or custom layer\n","Traversing inside container or custom layer\n","Found Linear layer: Linear(in_features=512, out_features=512, bias=False)\n","Found Linear layer name: wq\n","Found Linear layer: Linear(in_features=512, out_features=512, bias=False)\n","Found Linear layer name: wk\n","Found Linear layer: Linear(in_features=512, out_features=512, bias=False)\n","Found Linear layer name: wv\n","Found Linear layer: Linear(in_features=512, out_features=512, bias=False)\n","Found Linear layer name: wo\n","Traversing inside container or custom layer\n","Found Linear layer: Linear(in_features=512, out_features=1536, bias=False)\n","Found Linear layer name: w1\n","Found Linear layer: Linear(in_features=1536, out_features=512, bias=False)\n","Found Linear layer name: w2\n","Found Linear layer: Linear(in_features=512, out_features=1536, bias=False)\n","Found Linear layer name: w3\n","Traversing inside container or custom layer\n","Traversing inside container or custom layer\n","Found Linear layer: Linear(in_features=512, out_features=512, bias=False)\n","Found Linear layer name: wq\n","Found Linear layer: Linear(in_features=512, out_features=512, bias=False)\n","Found Linear layer name: wk\n","Found Linear layer: Linear(in_features=512, out_features=512, bias=False)\n","Found Linear layer name: wv\n","Found Linear layer: Linear(in_features=512, out_features=512, bias=False)\n","Found Linear layer name: wo\n","Traversing inside container or custom layer\n","Found Linear layer: Linear(in_features=512, out_features=1536, bias=False)\n","Found Linear layer name: w1\n","Found Linear layer: Linear(in_features=1536, out_features=512, bias=False)\n","Found Linear layer name: w2\n","Found Linear layer: Linear(in_features=512, out_features=1536, bias=False)\n","Found Linear layer name: w3\n","Found Linear layer: Linear(in_features=512, out_features=87, bias=False)\n","Found Linear layer name: output\n","{'wv', 'w1', 'output', 'wq', 'w2', 'wk', 'wo', 'w3'}\n"]}]},{"cell_type":"code","source":["#LoRA 정의\n","# 기본 모델 정의\n","class layer_test(nn.Module):\n","    def __init__(self, input_dim,hidden_dim, output_dim):\n","        super(layer_test, self).__init__()\n","\n","        self.layer1 = nn.Linear(input_dim,hidden_dim)\n","        self.layer2 = nn.Linear(hidden_dim,output_dim)\n","    def forward(self, x):\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        return x\n","\n","class LoRALayer(torch.nn.Module):\n","    def __init__(self, in_dim, out_dim, rank, alpha, device):\n","        super().__init__()\n","        self.device = device\n","        std_dev = 1 / torch.sqrt(torch.tensor(rank).float())\n","        self.A = torch.nn.Parameter(torch.randn(in_dim, rank) * std_dev).to(self.device)\n","\n","        self.B = torch.nn.Parameter(torch.zeros(rank, out_dim)).to(self.device)\n","\n","        self.alpha = alpha\n","\n","\n","    def forward(self, x):\n","        x = self.alpha * (x @  self.A @ self.B)\n","\n","        return x.to(self.device)\n","\n","\n","class LinearWithLoRA(torch.nn.Module):\n","    def __init__(self, linear, rank, alpha, model_device=\"cpu\", lora_device=\"cpu\"):\n","        super().__init__()\n","        self.linear = linear\n","        self.lora = LoRALayer(\n","            linear.in_features, linear.out_features, rank, alpha, device=lora_device\n","        )\n","        self.model_device = model_device\n","        self.lora_device = lora_device\n","        self.enabled = True\n","\n","\n","    def forward(self, x):\n","        if self.enabled == True:\n","            return self.linear(x) + (self.lora(x.to(self.lora_device))).to(self.model_device)\n","        else:\n","            return self.linear(x)"],"metadata":{"id":"47dlpF36edKz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from functools import partial\n","import copy\n","model.to('cpu')\n","for param in model.parameters():\n","    param.requires_grad = False\n","model_lora=copy.deepcopy(model)\n","\n","lora_params = []\n","assign_lora = partial(LinearWithLoRA, rank=2, alpha=1, model_device=\"cpu\", lora_device=\"cpu\")\n","lora_device = \"cpu\"\n","'wq', 'w1', 'wk', 'w2', 'wo', 'w3', 'output', 'wv'\n","wq = True\n","wk = True\n","wv = True\n","w1 = True\n","w2 = True\n","w3 = True\n","wo = True\n","\n","out = True\n","for layer in model_lora.layers:\n","    print(layer)\n","    # if l1 == True:\n","\n","    #     layer.layer1 = assign_lora(layer.layer1)\n","    #     # print(list(layer.layer1.lora.parameters()))\n","    #     layer.layer1.lora.to(lora_device)\n","    #     layer.layer1.lora_device = lora_device\n","\n","    #     lora_params.extend(list(layer.layer1.lora.parameters()))\n","\n","    if wq:\n","        layer.attention.wq = assign_lora(layer.attention.wq)\n","        layer.attention.wq.lora.to(lora_device)\n","        layer.attention.wq.lora_device = lora_device\n","        lora_params.extend(list(layer.attention.wq.lora.parameters()))\n","    if wk:\n","        layer.attention.wk = assign_lora(layer.attention.wk)\n","        layer.attention.wk.lora.to(lora_device)\n","        layer.attention.wk.lora_device = lora_device\n","        lora_params.extend(list(layer.attention.wk.lora.parameters()))\n","\n","    if wv:\n","        layer.attention.wv = assign_lora(layer.attention.wv)\n","        layer.attention.wv.lora.to(lora_device)\n","        layer.attention.wv.lora_device = lora_device\n","        lora_params.extend(list(layer.attention.wv.lora.parameters()))\n","    if wo:\n","        layer.attention.wo = assign_lora(layer.attention.wo)\n","        layer.attention.wo.lora.to(lora_device)\n","        layer.attention.wo.lora_device = lora_device\n","        lora_params.extend(list(layer.attention.wo.lora.parameters()))\n","\n","    if w1:\n","        layer.feed_forward.w1 = assign_lora(layer.feed_forward.w1)\n","        layer.feed_forward.w1.lora.to(lora_device)\n","        layer.feed_forward.w1.lora_device = lora_device\n","        lora_params.extend(list(layer.feed_forward.w1.lora.parameters()))\n","\n","    if w2:\n","        layer.feed_forward.w2 = assign_lora(layer.feed_forward.w2)\n","        layer.feed_forward.w2.lora.to(lora_device)\n","        layer.feed_forward.w2.lora_device = lora_device\n","        lora_params.extend(list(layer.feed_forward.w2.lora.parameters()))\n","\n","    if w3:\n","        layer.feed_forward.w3 = assign_lora(layer.feed_forward.w3)\n","        layer.feed_forward.w3.lora.to(lora_device)\n","        layer.feed_forward.w3.lora_device = lora_device\n","        lora_params.extend(list(layer.feed_forward.w3.lora.parameters()))\n","\n","\n","\n","\n","if out == True:\n","    print(model_lora.output)\n","\n","    model_lora.output = assign_lora(model_lora.output)\n","    model_lora.output.lora.to(lora_device)\n","    model_lora.output.lora_device = lora_device\n","    lora_params.extend(list(model_lora.output.lora.parameters()))\n","\n","# model_lora.output = assign_lora(model_lora.output)\n","# print(model_lora)\n","total_params = sum(p.numel() for p in model_lora.parameters())\n","total_params\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W27mcJLCehSl","executionInfo":{"status":"ok","timestamp":1713934854796,"user_tz":-540,"elapsed":304,"user":{"displayName":"진이준","userId":"14331068232004822154"}},"outputId":"c24b50b6-fd13-4475-db3a-a362d149292e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["EncoderBlock(\n","  (attention): SelfAttention(\n","    (wq): Linear(in_features=512, out_features=512, bias=False)\n","    (wk): Linear(in_features=512, out_features=512, bias=False)\n","    (wv): Linear(in_features=512, out_features=512, bias=False)\n","    (wo): Linear(in_features=512, out_features=512, bias=False)\n","  )\n","  (feed_forward): FeedForward(\n","    (w1): Linear(in_features=512, out_features=1536, bias=False)\n","    (w2): Linear(in_features=1536, out_features=512, bias=False)\n","    (w3): Linear(in_features=512, out_features=1536, bias=False)\n","  )\n","  (attention_norm): RMSNorm()\n","  (ffn_norm): RMSNorm()\n",")\n","EncoderBlock(\n","  (attention): SelfAttention(\n","    (wq): Linear(in_features=512, out_features=512, bias=False)\n","    (wk): Linear(in_features=512, out_features=512, bias=False)\n","    (wv): Linear(in_features=512, out_features=512, bias=False)\n","    (wo): Linear(in_features=512, out_features=512, bias=False)\n","  )\n","  (feed_forward): FeedForward(\n","    (w1): Linear(in_features=512, out_features=1536, bias=False)\n","    (w2): Linear(in_features=1536, out_features=512, bias=False)\n","    (w3): Linear(in_features=512, out_features=1536, bias=False)\n","  )\n","  (attention_norm): RMSNorm()\n","  (ffn_norm): RMSNorm()\n",")\n","EncoderBlock(\n","  (attention): SelfAttention(\n","    (wq): Linear(in_features=512, out_features=512, bias=False)\n","    (wk): Linear(in_features=512, out_features=512, bias=False)\n","    (wv): Linear(in_features=512, out_features=512, bias=False)\n","    (wo): Linear(in_features=512, out_features=512, bias=False)\n","  )\n","  (feed_forward): FeedForward(\n","    (w1): Linear(in_features=512, out_features=1536, bias=False)\n","    (w2): Linear(in_features=1536, out_features=512, bias=False)\n","    (w3): Linear(in_features=512, out_features=1536, bias=False)\n","  )\n","  (attention_norm): RMSNorm()\n","  (ffn_norm): RMSNorm()\n",")\n","EncoderBlock(\n","  (attention): SelfAttention(\n","    (wq): Linear(in_features=512, out_features=512, bias=False)\n","    (wk): Linear(in_features=512, out_features=512, bias=False)\n","    (wv): Linear(in_features=512, out_features=512, bias=False)\n","    (wo): Linear(in_features=512, out_features=512, bias=False)\n","  )\n","  (feed_forward): FeedForward(\n","    (w1): Linear(in_features=512, out_features=1536, bias=False)\n","    (w2): Linear(in_features=1536, out_features=512, bias=False)\n","    (w3): Linear(in_features=512, out_features=1536, bias=False)\n","  )\n","  (attention_norm): RMSNorm()\n","  (ffn_norm): RMSNorm()\n",")\n","Linear(in_features=512, out_features=87, bias=False)\n"]},{"output_type":"execute_result","data":{"text/plain":["13808302"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["print(model.parameters())\n","\n","total_params = sum(p.numel() for p in model.parameters())\n","total_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O5J3QDwTeiwI","executionInfo":{"status":"ok","timestamp":1713934865337,"user_tz":-540,"elapsed":791,"user":{"displayName":"진이준","userId":"14331068232004822154"}},"outputId":"aa9bed7c-f999-42cb-e98d-b65463adff1f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<generator object Module.parameters at 0x7eb1c03c4740>\n"]},{"output_type":"execute_result","data":{"text/plain":["13725184"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# 모델의 파라미터 중 GPU에 있는 파라미터만 선택하여 옵티마이저에 전달\n","lora_opt = torch.optim.Adam(lora_params, lr=0.001)"],"metadata":{"id":"NPvA9yqzesXq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epoch = 100\n","device = \"cpu\"\n","for i in range(epoch):\n","    loss=train_loop(model_lora, lora_opt, loss_fn, train_dataloader, device)\n","    if (i+1) % 3 == 0:\n","        print(f\"epoch {i+1} || \" +str(loss))\n","\n","    if (i+1) % 100 == 0:\n","        train_loop(model_lora, lora_opt, loss_fn, train_dataloader, device, print_random=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":559},"id":"oJwkQh1seo2y","executionInfo":{"status":"error","timestamp":1713934884587,"user_tz":-540,"elapsed":3249,"user":{"displayName":"진이준","userId":"14331068232004822154"}},"outputId":"51510875-d565-4c03-e10c-943f3378e161"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 3 || 2.602139472961426\n","epoch 6 || 1.2802064418792725\n","epoch 9 || 0.46481025218963623\n","epoch 12 || 0.16624602675437927\n","epoch 15 || 0.10203269869089127\n","epoch 18 || 0.06499260663986206\n","epoch 21 || 0.03792702034115791\n","epoch 24 || 0.023019518703222275\n","epoch 27 || 0.01480775885283947\n","epoch 30 || 0.01159036997705698\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-47483aa858cf>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_lora\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlora_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch {i+1} || \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-7d65e2b4a61e>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, opt, loss_fn, dataloader, device, print_random)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# X, y_input 및 tgt_mask를 전달하여 표준 training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLH_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPad_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m# print(str(X.size()) + \" >> \"+str(pred.size()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# print(y_expected.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-6096ec7b7e4a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tokens, LH_mask, Pad_mask)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m#consecutively apply all the encoder layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mLH_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-9bd9ec555749>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, LH_mask, Pad_mask)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m#(B, seq_len, dim) + (B, seq_len, dim) --> (B, seq_len, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mLH_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-9bd9ec555749>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mx_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswish\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-8c8713dedf22>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlora\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlora_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["prompt_ = [\"what is happiness\", \"can you make decisions\",\"are you human\" ,\"how are you\",\"who is john\",\"who is nice\"]\n","model_lora.eval()\n","prompt_tok = tokenizer.Encode(prompt_)\n","end_tok = tokenizer.Encode([\"<end>\"])[-1,-1]\n","max_length = 10\n","total_output = prompt_tok.to(device)\n","# print(total_output)\n","for _ in range(max_length):\n","    out=model_lora(total_output,LH_mask = True, Pad_mask = True)\n","\n","    out=torch.argmax(out, dim=-1)\n","    # print(out[:,-1][0])\n","    # if out[:,-1][0] == end_tok:\n","    #     break\n","\n","    # print( out[:,-1].unsqueeze(-1))\n","    total_output = torch.cat((total_output, out[:,-1].unsqueeze(-1)), 1)\n","\n","tokenizer.Decode(total_output)\n","\n","\n","###\n","# \"what is happiness\": \"a state of well-being <end>\",\n","# \"can you make decisions\": \"I can make choices based on data <end>\",\n","# \"are you human\": \"I am an AI model <end>\"\n","\n","# \"how are you\": \"i am fine <end>\",\n","# \"who is john\": \"a nice person <end>\",\n","# \"who is nice\": \"john <end>\","],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QdmNib9aes-l","executionInfo":{"status":"ok","timestamp":1713934897401,"user_tz":-540,"elapsed":1228,"user":{"displayName":"진이준","userId":"14331068232004822154"}},"outputId":"745c8dbe-a3ac-4181-bc88-e2bb51fbf32e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-11-50c272836007>:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  index_batch = torch.tensor(x).cpu().numpy().tolist()\n"]},{"output_type":"execute_result","data":{"text/plain":["['what is happiness  a state of well-being <end>',\n"," 'can you make decisions i can make choices based on data <end>',\n"," 'are you human  i am an ai model <end>',\n"," 'how are you  i am an ai model <end>',\n"," 'who is john  a state of well-being <end>',\n"," 'who is nice  john <end>']"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":[],"metadata":{"id":"s-iaQb9Eewi4"},"execution_count":null,"outputs":[]}]}